      # Default values for the generator
      # this file can be used as a template for a custom configuration
      # or to know about the different variables available for the generator
      platys:
          platform-name: 'default'
          platform-stack: 'trivadis/platys-modern-data-platform'
          platform-stack-version: '1.16.0-preview'
          structure: 'flat'
      # ===== Global configuation, valid for all or a group of services ========
      # Timezone, use a Linux string such as Europe/Zurich or America/New_York
      use_timezone: ''
      # the name of the repository to use for private images, which are not on docker hub (currently only Oracle images)
      private_docker_repository_name: 'trivadis'
      # the UID to use when using the "user" property in a service to override the user inside the container
      uid: '1000'

      data_centers: 'dc1,dc2'
      data_center_to_use: 0

      copy_cookbook_data_folder: true
      
      # ========================================================================
      # External Services
      # ========================================================================

      external:
        KAFKA_enable: false
        KAFKA_bootstrap_servers:
        KAFKA_security_protocol: 
        KAFKA_sasl_mechanism: 

        SCHEMA_REGISTRY_enable: false
        SCHEMA_REGISTRY_url:

        S3_enable: false
        S3_endpoint:
        S3_default_region:
        S3_path_style_access: false

        ADLS_enable: false
        ADLS_storage_account:      
      
      PROVISIONING_DATA_enable: false
      
      #
      # ===== Apache Kafka ========
      #
      KAFKA_enable: true
      # one of enterprise, community
      KAFKA_edition: 'community'
      KAFKA_volume_map_data: false
      KAFKA_use_standard_port_for_external_interface: true
      KAFKA_datacenters: 1
      KAFKA_broker_nodes: 3
      KAFKA_broker_first_port: 9092
      KAFKA_use_kraft_mode: false
      KAFKA_internal_replication_factor: 3
      KAFKA_delete_topic_enable: true
      KAFKA_auto_create_topics_enable: false
      KAFKA_message_timestamp_type: CreateTime
      KAFKA_jmx_monitoring_prometheus_enable: false
      # KAFKA_log_segment_bytes:
      # KAFKA_log_retention_ms:
      # KAFKA_log_retention_hours:
      # KAFKA_log_retention_bytes:
      # KAFKA_compression_type:
      # KAFKA_min_insync_replicas:
      # KAFKA_replica_selector_class: org.apache.kafka.common.replica.RackAwareReplicaSelector
      KAFKA_confluent_log_placement_constraints:
      KAFKA_confluent_tier_feature: false
      KAFKA_confluent_tier_enable: false
      KAFKA_confluent_tier_backend: S3
      KAFKA_confluent_tier_s3_bucket: kafka-logs
      KAFKA_confluent_tier_s3_region: us-east-1
      KAFKA_confluent_tier_s3_aws_endpoint_override:
      KAFKA_confluent_tier_s3_force_path_style_access: false
      KAFKA_confluent_tier_local_hotset_bytes:
      KAFKA_confluent_tier_local_hotset_ms:
      KAFKA_confluent_tier_archiver_num_threads:
      KAFKA_confluent_tier_fetcher_num_threads:
      KAFKA_confluent_tier_topic_delete_check_interval_ms:
      KAFKA_confluent_tier_metadata_replication_factor: 1
      KAFKA_log4j_root_level: 'INFO'
      KAFKA_log4j_loggers: ''   
      KAFKA_tools_log4j_level: 'INFO' 

      #kafka connect
      KAFKA_CONNECT_enable: true
      KAFKA_CONNECT_nodes: 2
      KAFKA_CONNECT_connectors: 'jcustenborder/kafka-connect-twitter:0.3.33'

      #
      # ===== Confluent ksqlDB ========
      #
      KAFKA_KSQLDB_enable: true
      # either 'cp' or 'oss'
      KAFKA_KSQLDB_edition: 'oss'
      KAFKA_KSQLDB_nodes: 1
      KAFKA_KSQLDB_internal_replication_factor: 1
      KAFKA_KSQLDB_suppress_enabled: false
      KAFKA_KSQLDB_suppress_buffer_size_bytes: -1
      KAFKA_KSQLDB_query_pull_table_scan_enabled: false
      KAFKA_KSQLDB_queries_file: ''
      KAFKA_KSQLDB_response_http_headers_config: ''
      KAFKA_KSQLDB_use_embedded_connect: false
      KAFAK_KSQLDB_connect_connectors: 
      KAFKA_KSQLDB_persistence_default_format_key: 'KAFKA'
      KAFKA_KSQLDB_persistence_default_format_value: ''

      KAFKA_SCHEMA_REGISTRY_UI_enable: true
      KAFKA_CONNECT_UI_enable: true

      KAFKACAT_enable: true
      KAFKA_AKHQ_enable: true
      
      #
      # ===== Schema Registry ========
      #
      SCHEMA_REGISTRY_enable: true
      # either "confluent", "apicurio"
      SCHEMA_REGISTRY_flavour: confluent
      SCHEMA_REGISTRY_nodes: 1

      # ===== Confluent Schema Registry ========
      CONFLUENT_SCHEMA_REGISTRY_use_zookeeper_election: false
      CONFLUENT_SCHEMA_REGISTRY_group_id: schema-registry
      CONFLUENT_SCHEMA_REGISTRY_replication_factor: 1
      CONFLUENT_SCHEMA_REGISTRY_leader_eligibility: true
      CONFLUENT_SCHEMA_REGISTRY_mode_mutability: true
      # One of "none", "backward", "backward_transitive", "forward", "forward_transitive", "full" or "full_transitive".
      CONFLUENT_SCHEMA_REGISTRY_schema_compatibility_level: backward
      CONFLUENT_SCHEMA_REGISTRY_log4j_root_loglevel: info
      CONFLUENT_SCHEMA_REGISTRY_debug: false
      
      # ===== Spark ========
      SPARK_enable: true
      SPARK_version: 2.4.5-hadoop2.8
      SPARK_workers: 2
      SPARK_jars_packages: 'org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.5'
      #SPARK_jars_packages: 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.0'
      SPARK_jars_excludes: ''

      SPARK_HISTORY_enable: true

      # ===== Apache Hive Metastore ========
      HIVE_METASTORE_enable: true

      # =====  Streamsets and stremsets edge ========
      STREAMSETS_enable: true

      # ===== Zeppelin ========
      ZEPPELIN_enable: true
      ZEPPELIN_version: 0.8.2-spark2.4-hadoop2.8

      # ===== RDBMS ========
      POSTGRESQL_enable: true
      POSTGRESQL_user: demo
   
       #
      # ===== Trino ========
      #
      TRINO_enable: true
      # "single" or "cluster" install
      TRINO_install: single
      TRINO_workers: 3
      # either starburstdata or oss
      TRINO_edition: 'oss'
      TRINO_hive_storage_format: ORC
      TRINO_hive_compression_codec: GZIP
      TRINO_kafka_table_names: ''
      TRINO_event_listener: ''
      TRINO_oracle_user: ''
      TRINO_oracle_password: ''
      TRINO_sqlserver_database: ''
      TRINO_sqlserver_user: ''
      TRINO_sqlserver_password: ''
      TRINO_starburstdata_use_license: false

      # Trino-CLI is enabled by default
      TRINO_CLI_enable: true
   
      # ===== Presto ========
      PRESTO_enable: false
      # "single" or "cluster" install
      PRESTO_install: single
      PRESTO_workers: 3
      # either prestodb or ahana
      PRESTO_edition: 'ahana'

      # ===== Dremio ========
      DREMIO_enable: true

      # ===== Apache Drill ========
      DRILL_enable: true

      #
      #=====  MinIO Object Storage ========
      #
      MINIO_enable: true
      MINIO_volume_map_data: false
      MINIO_datacenters: 1
      # "single" or "cluster"
      MINIO_install: 'single'
      MINIO_nodes: 1
      MINIO_access_key: V42FCGRVMK24JJ8DHUYG
      MINIO_secret_key: bKhWxVF3kQoLY9kFmt91l+tDrEoZjqnWXzY9Eza
      # add additional buckets, comma separated, admin-bucket will be created by default
      MINIO_default_buckets: ''
      MINIO_browser_enable: true
      
      AWSCLI_enable: true

      